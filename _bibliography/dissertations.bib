---
---
@article{VENUGOPAL202277,
  abbr={JPDC22},
  title = {Targeting a light-weight and multi-channel approach for distributed stream processing},
  journal = {Journal of Parallel and Distributed Computing},
  volume = {167},
  pages = {77-96},
  year = {2022},
  issn = {0743-7315},
  doi = {https://doi.org/10.1016/j.jpdc.2022.04.022},
  url = {https://www.sciencedirect.com/science/article/pii/S0743731522001022},
  author = {Vinu Ellampallil Venugopal and Martin Theobald and Damien Tassetti and Samira Chaychi and Amal Tawakuli},
  keywords = {Distributed stream processing systems, Dataflow programming, Asynchronous iterative routing, Stateful windowed operators},
  abstract = {Processing high-throughput data-streams has become a major challenge in areas such as real-time event monitoring, complex dataflow processing, and big data analytics. While there has been tremendous progress in distributed stream processing systems in the past few years, the high-throughput and low-latency (a.k.a. high sustainable-throughput) requirement of modern applications is pushing the limits of traditional data processing infrastructures. This paper introduces a new distributed stream processing engine (DSPE), called Asynchronous Iterative Routing (or simply “AIR”), which implements a light-weight, dynamic sharding protocol. AIR expedites direct and asynchronous communication among all the worker nodes via a channel-like communication protocol on top of the Message Passing Interface (MPI), thereby completely avoiding the need for a dedicated driver node. The system adopts a new progress-tracking protocol, called hew-meld, which has been experimentally observed to show a low processing latency on our asynchronous master-less architecture when compared to the conventional low-watermark technique. The current version of AIR is also equipped with two fault tolerance and recovery strategies namely checkpointing & rollback and replication. With its unique design, AIR scales out particularly well to multi-core HPC architectures; specifically, we deployed it on clusters with up to 16 nodes and 448 cores (thus reaching a peak of 435.3 million events and 55.14 GB of data processed per second), which we found to significantly outperform existing DSPEs.}
}

@inproceedings{DBLP:conf/comad/TosiVT22,
abbr={CODS-COMAD22},
  author    = {Mauro Dalle Lucca Tosi and
               Vinu Ellampallil Venugopal and
               Martin Theobald},
  title     = {Convergence time analysis of Asynchronous Distributed Artificial Neural
               Networks},
  booktitle = {{CODS-COMAD} 2022: 5th Joint International Conference on Data Science
               {\&} Management of Data (9th {ACM} {IKDD} {CODS} and 27th COMAD),
               Bangalore, India, January 8 - 10, 2022},
  pages     = {314--315},
  publisher = {{ACM}},
  year      = {2022},
  url       = {https://doi.org/10.1145/3493700.3493758},
  doi       = {10.1145/3493700.3493758},
  timestamp = {Thu, 23 Jun 2022 19:58:58 +0200},
  biburl    = {https://dblp.org/rec/conf/comad/TosiVT22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}































